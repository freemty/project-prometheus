<html>

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Prometheus: 3D-Aware Latent Diffusion Models for Feed-Forward Text-to-3D Scene Generation</title>
  <!-- <title>MonST3R: A Simple Approach for Estimating Geometry in the Presense of Motion</title> -->
  <link href="./files/style.css" rel="stylesheet">
  <link rel="icon" href="icons/prometheus_icon.png" type="image/png">
  <script type="text/javascript" src="./files/jquery.mlens-1.0.min.js"></script>
  <script type="text/javascript" src="./files/jquery.js"></script>
  <style>
    .divider {
      border-right: 2px dashed #737373;
      width: 2px;
    }
  </style>
  <style>
    .divider_horizontal {
      border-top: 2px dashed #737373;
      display: block;
      width: 100%;
      margin: 10px 0;
    }
  </style>
  <!-- Begin new styles from demos page -->
  <style>
    body {
      padding: 2em;
      font-family: sans-serif;
    }

    iframe {
      border-radius: 0.5em;
      width: 27.5em;
      height: 27.5em;
      border: none;
      box-shadow: 0 0 1em 0em rgba(0, 0, 0, 0.15);
    }

    @media (max-width: 768px) {
      iframe {
        width: 100%;
        height: 30em;
      }
    }

    a,
    a:link {
      color: #777;
    }

    /* Styles for the instruction icons and text */
    .instructions {
      display: flex;
      justify-content: center;
      align-items: center;
      flex-wrap: wrap;
      gap: 1.2em;
      text-align: center;
      padding: 0.6em;
    }

    .instruction-item {
      display: flex;
      align-items: center;
      gap: 0.5em;
      font-size: 1.2em;
    }

    .instruction-item img {
      width: 36px;
      height: 36px;
    }

    .instructions_small {
      display: flex;
      justify-content: center;
      align-items: center;
      flex-wrap: wrap;
      gap: 1em;
      text-align: center;
      padding: 0.5em;
    }

    .instruction-item_small {
      display: flex;
      align-items: center;
      gap: 0.3em;
      font-size: 1.0em;
    }

    .instruction-item_small img {
      width: 30px;
      height: 30px;
    }

    /* New styles for clickable images and iframe display */
    .clickable-image {
      max-width: 100%;
      max-height: 200px;
      object-fit: cover;
      cursor: pointer;
      border-radius: 0.5em;
      box-shadow: 0 0 1em 0em rgba(0, 0, 0, 0.15);
    }

    #iframe-display-section {
      margin-top: 2em;
      text-align: center;
      border: 1px solid #ddd;
      padding: 1em;
      background-color: #f9f9f9;
      border-radius: 0.5em;
      box-shadow: 0 0 1em 0em rgba(0, 0, 0, 0.15);
    }

  </style>
  <!-- End new styles -->
</head>

    <h1 style="line-height: 0.75;">
      <!-- <img src="./icons/prometheus_icon_full.png" alt="Prometheus Icon" style="width: 640px; vertical-align: middle;"> <br> -->
        <img src="./icons/prometheus_icon_wbg.png" alt="Prometheus Icon" style="width: 80px; vertical-align: middle;">
      <strong>
        <span style="font-weight: bold; color: rgb(255, 69, 92);"> Prometheus</span> 
        : 3D-Aware Latent Diffusion Models for <br> Feed-Forward Text-to-3D Scene Generation</strong>
    </h1>
    <p id="authors">
      <span>
        <a href="https://github.com/freemty"> Yuanbo Yang<sup>1,*</sup></a>
      </span>
      <span>
        <a href="https://jiahao-shao1.github.io/">Jiahao Shao<sup>1,*</sup></a>
      </span>
      <span>
        <a href="https://github.com/imlixinyang">Xinyang Li<sup>2</sup></a>
      </span>
      <span>
        <a href="https://shenyujun.github.io/">Yujun Shen<sup>3</sup></a>
      </span>
      <span>
        <a href="https://www.cvlibs.net/">Andreas Geiger<sup>4</sup></a>
      </span>
      <span>
        <a href="https://yiyiliao.github.io/">Yiyi Liao<sup>1,+</sup></a>
      </span>

      <br>
      <span class="institution">
        <sup>1</sup> Zhejiang University</a>
        <sup>2</sup> Xiamen University</a>
        <sup>3</sup> Ant Group</a>
        <sup>4</sup> University of T√ºbingen</span>
        <!-- <a href="https://bair.berkeley.edu/"><sup>1</sup> Zhejiang University</a>
        <a href="https://deepmind.google/"><sup>2</sup> Xiamen University</a>
        <a href="https://stability.ai/"><sup>3</sup> Ant Group</a>
        <a href="https://www.ucmerced.edu/"><sup>4</sup> AA</a></span> -->
        <span class="institution"></span>
      <span class="institution">(+: corresponding author, *: equal contribution)</span>
    </p>
    <body>

    <div class="content">
    <!-- <br>
        <img src="./files/teaser_monst3r.png" class="teaser-gif" style="width:100%;"><br> -->

    <!-- add video files/teaser_vid_v2_lowres.mp4 -->
    <video width="100%" controls>
      <iframe width="560" height="315" src="https://www.youtube.com/embed/UxvLuj-mCHY?si=--mU2Pa7UOY0K0C5"
            title="YouTube video player" frameborder="0"
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
            referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
      <source src="./files/demo.mp4" type="video/mp4">
    </video>


    <!-- <script>

      var video = document.getElementById('myVideo');
      video.currentTime = 4;
      video.addEventListener('loadedmetadata', function () {
        video.pause();
      });
    </script> -->
    <br>
    <br>

    <a style="text-align:center">
      <font size="+1.5">
        We present a novel method for feed-forward scene-level 3D generation. At its core, our approach <em>harnesses
        the power of 2D priors to fuel generalizable and efficient 3D synthesis </em>‚Äì hence our name, <strong><span style="font-weight: bold; color: rgb(255, 69, 92);">Prometheusüî•</span></strong>.

      </font>
    
    <font size="+2">
      <p style="text-align: center;">
        <a href="./files/prometheus_paper.pdf" target="_blank">[Paper]</a> &nbsp;&nbsp;&nbsp;&nbsp;
        <!-- <a href="https://github.com/Junyi42/monst3r" target="_blank">[Arxiv]</a> &nbsp;&nbsp;&nbsp;&nbsp; -->
        <a href="page1.html" target="_blank" style="font-weight: bold; color: rgb(255, 69, 92);">[Interactive Resultsüî•]</a>
        &nbsp;&nbsp;&nbsp;&nbsp;
        <a href="https://github.com/XDimLab/Prometheus" target="_blank">[Code]</a>&nbsp;&nbsp;&nbsp;&nbsp;
        <!-- <a href="https://x.com/junyi42/status/1770799360353145037" target="_blank">[X Post]</a>&nbsp;&nbsp;&nbsp;&nbsp; -->
        <a href=" " target="_blank">[Video]</a>&nbsp;&nbsp;&nbsp;&nbsp;
        <a href="files/bibtex.txt" target="_blank">[BibTeX]</a>
      </p>
    </font>
    </div>
<div class="content">
  <h2>Interactive 3D Scene Visualization</h2>
  <font size="+1">
    <p>Explore the text-to-3D generation results of <strong><span
          style="font-weight: bold; color: rgb(255, 69, 92);">Prometheusüî•</span></strong> on various scenes. You can select a scene by clicking the
          corresponding multiview image.</p> 
  </font>

  <!-- Downsampling note -->
  <!-- <p style="text-align: center; font-size: 1em; padding: 0em; color: #555;">
    (Results are pruned to no more than 200K 3DGS primitives for efficient online rendering)
  </p> -->

  <!-- Top section: Images and captions -->
  <div id="image-captions-section" style="
        display: flex;
        flex-wrap: wrap;
        justify-content: center;
        align-items: center;
        gap: 2em;
    ">

    <div class="image-caption-item" style="text-align: center; flex: 1 1 45%;">
      <div style="margin-top: 10px;"><i>A bridge spans across the width of the image,
          connecting two sides separated by water‚õ∞Ô∏è</i></div>
      <img
        src="recordings/A_bridge_spans_across_the_width_of_the_image,_connecting_two_sides_separated_by_water._The_scene_is_dominated_by_gray_an/0/image.png"
        alt="Thumbnail 1" class="clickable-image"
        data-iframe-src="https://jiahao-shao1.github.io/build/?playbackPath=https://freemty.github.io/project-prometheus/recordings/A_bridge_spans_across_the_width_of_the_image,_connecting_two_sides_separated_by_water._The_scene_is_dominated_by_gray_an/0/viser.viser">
    
    </div>
    
    <!-- Second item -->
    <div class="image-caption-item" style="text-align: center; flex: 1 1 45%;">
      <div style="margin-top: 10px;"><i>A large, white luxury yacht floats serenely above the calm waters of an ocean</i> üõ•Ô∏è</div>
      <img
        src="recordings/A_large,_white_luxury_yacht_floats_serenely_above_the_calm_waters_of_an_ocean,_surrounded_by_a_hazy_atmosphere_that_give/0/image.png"
        alt="Thumbnail 2" class="clickable-image"
        data-iframe-src="https://jiahao-shao1.github.io/build/?playbackPath=https://freemty.github.io/project-prometheus/recordings/A_large,_white_luxury_yacht_floats_serenely_above_the_calm_waters_of_an_ocean,_surrounded_by_a_hazy_atmosphere_that_give/0/viser.viser">
    
    </div>

    <!-- First item -->
    <div class="image-caption-item" style="text-align: center; flex: 1 1 45%;">
          <div style="margin-top: 10px;"><i>A desert landscape is visible in the image, with houses scattered across it. The terrain is flat and covered with sparse grass</i> üèúÔ∏è</div>
          <img
            src="recordings/A_desert_landscape_is_visible_in_the_image,_with_houses_scattered_across_it._The_terrain_is_flat_and_covered_with_sparse/0/image/A desert landscape is visible in the image, with h_.png"
            alt="Thumbnail 1" class="clickable-image"
            data-iframe-src="https://jiahao-shao1.github.io/build/?playbackPath=https://freemty.github.io/project-prometheus/recordings/A_desert_landscape_is_visible_in_the_image,_with_houses_scattered_across_it._The_terrain_is_flat_and_covered_with_sparse/0/viser.viser">
        
      </div>

      <div class="image-caption-item" style="text-align: center; flex: 1 1 45%;">
        <div style="margin-top: 10px;"><i>A bustling coral reef, alive with the vibrant dance of fish and swaying plantsü™∏</i></div>
        <img
          src="recordings/A_bustling_coral_reef,_alive_with_the_vibrant_dance_of_fish_and_swaying_plants/0/image/A bustling coral reef, alive with the vibrant danc_.png"
          alt="Thumbnail 1" class="clickable-image"
          data-iframe-src="https://jiahao-shao1.github.io/build/?playbackPath=https://freemty.github.io/project-prometheusrecordings/A_bustling_coral_reef,_alive_with_the_vibrant_dance_of_fish_and_swaying_plants/0/viser.viser">
      
      </div>

      <div class="image-caption-item" style="text-align: center; flex: 1 1 45%;">
        <div style="margin-top: 10px;"><i>A cozy living room_with warm lighting has a wooden floor and features two armchairs
            centered on a plush rug</i> ü™ë</div>
        <img
          src="recordings/A_cozy_living_room_with_warm_lighting_has_a_wooden_floor_and_features_two_armchairs_centered_on_a_plush_rug._Behind_the_/0/image/A cozy living room with warm lighting has a wooden_.png"
          alt="Thumbnail 2" class="clickable-image"
          data-iframe-src="https://jiahao-shao1.github.io/build/?playbackPath=https://freemty.github.io/project-prometheus/recordings/A_cozy_living_room_with_warm_lighting_has_a_wooden_floor_and_features_two_armchairs_centered_on_a_plush_rug._Behind_the_/0/viser.viser">
      </div>

      <!-- Second item -->
      <div class="image-caption-item" style="text-align: center; flex: 1 1 45%;">
          <div style="margin-top: 10px;"><i>A gray-roofed house with a_garage sits amidst green grass and scattered treesüè°</i></div>
          <img
            src="recordings/A_gray-roofed_house_with_a_garage_sits_amidst_green_grass_and_scattered_trees._Vehicles_are_parked_in_the_driveway,_whic/0/image/A gray-roofed house with a garage sits amidst gree_.png"
            alt="Thumbnail 2" class="clickable-image"
            data-iframe-src="https://jiahao-shao1.github.io/build/?playbackPath=https://freemty.github.io/project-prometheus/recordings/A_gray-roofed_house_with_a_garage_sits_amidst_green_grass_and_scattered_trees._Vehicles_are_parked_in_the_driveway,_whic/0/viser.viser">
        
      </div>

        <!-- First item -->
        <div class="image-caption-item" style="text-align: center; flex: 1 1 45%;">
          <div style="margin-top: 10px;"><i>A blooming potted orchid with purple flowersüå∑</i></div>
          <img
            src="recordings/A_blooming_potted_orchid_with_purple_flowers/0/image/A blooming potted orchid with purple flowers_.png"
            alt="Thumbnail 1" class="clickable-image"
            data-iframe-src="https://jiahao-shao1.github.io/build/?playbackPath=https://freemty.github.io/project-prometheus/recordings/A_blooming_potted_orchid_with_purple_flowers/0/viser.viser">
        
        </div>
        
        <!-- Second item -->
        <div class="image-caption-item" style="text-align: center; flex: 1 1 45%;">
          <div style="margin-top: 10px;"><i>A campfire üî•</i></div>
          <img src="recordings/a_campfire/0/image/a campfire_.png" alt="Thumbnail 2" class="clickable-image"
            data-iframe-src="https://jiahao-shao1.github.io/build/?playbackPath=https://freemty.github.io/project-prometheus/recordings/a_campfire/0/viser.viser">
        </div>

    <!-- Add more items as needed -->
  </div>

  <!--Iframe display area -->
  <div id="iframe-display-section" style="
        margin-top: 2em;
        text-align: center;
        border: 1px solid #ddd;
        padding: 1em;
        background-color: #f9f9f9;
    ">
    <h3>Interactive 3D Scene</h3>
      <div class="instructions" style="margin-top: -1em;">
        <div class="instruction-item" style="display: flex; align-items: center;">
          <img src="icons/left-click.png" alt="Left Click" style="margin-right: 0px;">
          <span>Drag with <em>left</em> click to <strong>rotate</strong> view</span>
        </div>
      
        <div class="instruction-item" style="display: flex; align-items: center; margin-top: 10px;">
          <img src="icons/scroll-wheel.png" alt="Scroll Wheel" style="margin-right: -5px;">
          <span>Scroll to <strong>zoom</strong> in/out</span>
        </div>
      
        <div class="instruction-item" style="display: flex; align-items: center; margin-top: 10px;">
          <img src="icons/right-click.png" alt="Right Click" style="margin-right: 0px;">
          <span>Drag with <em>right</em> click to <strong>move</strong> view</span>
        </div>
      </div>
      
      <div class="instructions_small">
        <div class="instruction-item_small" style="display: flex; align-items: center; margin-top: -15px;">
          <img src="icons/letter-w.png" alt="W" style="margin-right: -10px;">
          <img src="icons/letter-s.png" alt="S" style="margin-right: 0px;">
          <span>Moving forward and backward</span>
        </div>
      
        <div class="instruction-item_small" style="display: flex; align-items: center; margin-top: -15px;">
          <img src="icons/letter-a.png" alt="A" style="margin-right: -10px;">
          <img src="icons/letter-d.png" alt="D" style="margin-right: 0px;">
          <span>Moving left and right</span>
        </div>
      
        <div class="instruction-item_small" style="display: flex; align-items: center; margin-top: -15px;">
          <img src="icons/letter-q.png" alt="Q" style="margin-right: -10px;">
          <img src="icons/letter-e.png" alt="E" style="margin-right: 0px;">
          <span>Moving upward and downward</span>
        </div>
      </div>


    <iframe id="iframe-display" style="width: 100%; height: 500px; border: none;"></iframe>
  </div>
</div>
<script>
  // JavaScript to handle the click event and load the iframe
  document.querySelectorAll('.clickable-image').forEach(image => {
    image.addEventListener('click', function () {
      const iframeSrc = this.getAttribute('data-iframe-src'); // Get the iframe source from the data attribute
      const iframeDisplay = document.getElementById('iframe-display');
      iframeDisplay.src = iframeSrc; // Set the iframe source
    });
  });

  // Set the default iframe source to the first scene on page load
  window.addEventListener('load', function () {
    const firstImage = document.querySelector('.clickable-image'); // Get the first image
    const iframeSrc = firstImage.getAttribute('data-iframe-src'); // Get its iframe source
    const iframeDisplay = document.getElementById('iframe-display');
    iframeDisplay.src = iframeSrc; // Set the iframe source
  });
</script>

  <!-- End new content -->

  <div class="content">
    <h2 style="text-align:center;">Abstract</h2>
    <font size="+1">
      <p>
      In this work, we introduce <strong><span style="font-weight: bold; color: rgb(255, 69, 92);">Prometheusüî•</span></strong>, a 3D-aware latent diffusion model for text-to-3D generation at both object and
      scene levels in seconds.
      We formulate 3D scene generation as multi-view, feed-forward, pixel-aligned 3D Gaussian generation within the latent
      diffusion paradigm.
      To ensure generalizability, we build our model upon pre-trained text-to-image generation model with only minimal
      adjustments, and further train it using a large number of images from both single-view and multi-view datasets.
      Furthermore, we introduce an RGB-D latent space into 3D Gaussian generation to disentangle appearance and geometry
      information, enabling efficient feed-forward generation of 3D Gaussians with better fidelity and geometry.
      Extensive experimental results demonstrate the effectiveness of our method in both feed-forward 3D Gaussian
      reconstruction and text-to-3D generation.
      </p>
      <img class="teaser-img" src="./files/teaser_p1.jpg" style="width:100%;margin-bottom: -10px;">
  </font>
  </div>

  
  <div class="content">
    <h2 style="text-align:center;">Method</h2>
    <!-- <p> For a video input consisting of more than two frames, we can aggregate all the pairwise pointmap results to build a global point cloud. </p> -->
    <img class="method-img" src="./files/method.jpg" style="width:100%;">
    <!-- <h3>
      <center>Dynamic global point cloud and camera pose estimation</center>
    </h3> -->
    <font size="+1">
      <strong>Method Overview:</strong> Our training process is divided into two stages. In stage 1, our objective is to train a <strong>GS-VAE</strong>. Utilizing multi-view images along with their corresponding pseudo depth maps and camera poses, our GS-VAE is designed to encode these multi-view RGB-D images, integrate cross-view information, and ultimately decode them into pixel-aligned 3DGS. In stage
      2, we focus on training a <strong>MV-LDM</strong>. We can generate multi-view RGB-D latents by sampling from randomly-sampled noise with
      trained MV-LDM.
    </font>

  </div>

  <div class="content">
    <h2>Stage1 Results: Feed-forward 3D Reconstruction</h2>
    <img class="summary-img" src="./files/stage1_quantitative.png" style="width:90%;">
    <p> <strong>Quantitatively</strong>: We compare our GS-VAE with baselines for generalizable reconstruction on <i>Tartanair</i>. </p>

    <img class="summary-img" src="./files/stage1_qualitative.png" style="width:100%; margin-top: 2px; margin-bottom: -5px;">
    <p> <strong>Qualitatively</strong>: We compare <strong><span style="font-weight: bold; color: rgb(255, 69, 92);">Prometheusüî•</span></strong> against baselines under varying difficulty settings. As overlap gradually decreases, the advantages of our method continue to grow. Moreover, as shown in the depth map, our method exhibits superior geometry quality across all settings.</p>
  </div>

  <div class="content">
    <h2>Stage2 Results: Text-to-3D Genetaion</h2>

    <img class="summary-img" src="./files/stage2_quantitative.png" style="width:100%;">
    <p> <strong>Quantitatively</strong>: We compare <strong><span
              style="font-weight: bold; color: rgb(255, 69, 92);">Prometheusüî•</span></strong> with baselines for text-to-3D
          generation utilizing text prompts from <i>T3Bench</i>. </p>

    <img class="summary-img" src="./files/stage2_qualitative.png" style="width:100%; margin-top: 2px; margin-bottom: 0px;">
    <p> <strong>Qualitatively (Object-level)</strong>: <strong><span
              style="font-weight: bold; color: rgb(255, 69, 92);">Prometheusüî•</span></strong> generates objects that align with
          the given
          description, incorporating rich background information and intricate details. </p>

    <img class="summary-img" src="./files/stage2_scenelevel.png" style="width:100%; margin-top: 2px; margin-bottom: 0px;">
    <p> <strong>Qualitatively (Scene-level)</strong>: Comparing with Director3D, our result better aligns with the text prompt and captures more details. </p>
    <!-- <p> <strong> More Text-to-3D Results </strong></p> -->

    <img class="summary-img" src="./files/teaser_p2.jpg" style="width:100%; margin-top: 10px; margin-bottom: -5px;">
    <h3 style="text-align:center;">More Text-to-3D Results: <a href="page1.html" target="_blank" style="font-weight: bold; color: rgb(255, 69, 92);">Hereüî•</a></h3>

  </div>

  <!-- <div class="content">
    <h2>Results - Joint Dense Reconstruction & Pose Estimation</h2>
    <p> <strong>Qualitatively</strong>, MonST3R outputs both reliable camera trajectories and geometry of dynamic scenes. </p>
    <img class="summary-img" src="./files/fig12_joint.png" style="width:85%; margin-top: 2px; margin-bottom: 0px;">
    <img class="summary-img" src="./files/fig11_joint.png" style="width:85%; margin-top: 10px; margin-bottom: -5px;">
    <h3>
      <center>Joint dense reconstruction and pose estimation results on DAVIS</center>
    </h3>
  </div>

  <div class="content">
    <h2>Results - Pairwise prediction</h2>
    <p> We also show the results of feed-forward pairwise pointmaps prediction. </p>
    <img class="summary-img" src="./files/fig13_pairwise.png" style="width:85%; margin-top: 2px; margin-bottom: 10px;">
    <a>
      <strong>Row 1</strong> demonstrates that even after fine-tuning, our method retains the ability to handle changing camera intrinsics. <strong>Rows 2 and 3</strong> demonstrate that our
method can handle ‚Äúimpossible‚Äù alignments that two frames have almost no overlap, even in the presence of motion, unlike DUSt3R that misaligns based on the foreground object. <strong>Rows 4 and 5</strong>
show that in addition to enabling the model to handle motion, our fine-tuning also has improved the model's ability to represent large-scale scenes, where DUSt3R predicts to be flat.
    </a>
  </div> -->

  <div class="content">
    <h2>BibTex</h2>
    <font size="-0.">
    <code> @article{yang2024prometheus,<br>
    &nbsp;&nbsp;title={Prometheus: 3D-Aware Latent Diffusion Models for Feed-Forward Text-to-3D Scene Generation},<br>
    &nbsp;&nbsp;author={Yuanbo, Yang and Jiahao, Shap and Xinyang, Li and Yujun, Shen and Andreas, Geiger and Yiyi, Liao},<br>
    <!-- &nbsp;&nbsp;journal={arXiv preprint arxiv:2410.03825},<br> -->
    &nbsp;&nbsp;year={2024}<br>
    } </code>
  </font>
  </div>
  
  <div class="content" id="acknowledgements">
    <p><strong>Acknowledgements</strong>:
      We borrow this template from <a href="https://monst3r-project.github.io/">Monst3R</a>, which is originally from <a href="https://dreambooth.github.io/">DreamBooth</a>. 
      The interactive 3DGS visualization is inspired by <a href="https://robot-see-robot-do.github.io/">Robot-See-Robot-Do</a>, and powered by <a href="https://github.com/nerfstudio-project/viser">Viser</a>. 
      We sincerely thank <a href="https://scholar.google.com/citations?hl=en&user=Ecy6lXwAAAAJ">Brent Yi</a> for his support in setting up the online visualization.
      <!-- Recycling a familiar <a href="https://chail.github.io/latent-composition/">template</a> ;). -->
    </p>
  </div>
</body>

</html>
